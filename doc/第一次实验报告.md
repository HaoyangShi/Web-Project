# @[TOC](新闻爬虫以及爬取结果查询网站搭建（一）)(新闻爬虫以及爬取结果查询网站搭建（一）)

# 实验要求
1、选取3-5个代表性的新闻网站（比如新浪新闻、网易新闻等，或者某个垂直领域权威性的网站比如经济领域的雪球财经、东方财富等，或者体育领域的腾讯体育、虎扑体育等等）建立爬虫，针对不同网站的新闻页面进行分析，爬取出编码、标题、作者、时间、关键词、摘要、内容、来源等结构化信息，存储在数据库中。
2、建立网站提供对爬取内容的分项全文搜索，给出所查关键词的时间热度分析。

## 技术要求
1、必须采用Node.JS实现网络爬虫
2、必须采用Node.JS实现查询网站后端，HTML+JS实现前端（尽量不要使用任何前后端框架）
# 爬虫准备工作
一共选了三个新闻网站进行爬虫，分别是**中国财经网**、**雪球网**、**网易新闻**，并且将爬取结果存储在postgresql中。
在本实验中，基于Node.js用Cheerio和Request实现了爬虫。下面将详细介绍基本环境搭配，各个爬虫的实现，功能实现过程等内容。

## Node.js 介绍与安装配置
### Node.js介绍
- Node.js 是一个开源与跨平台的 JavaScript 运行时环境。 它是一个可用于几乎任何项目的流行工具！

- Node.js 在浏览器外运行 V8 JavaScript 引擎（Google Chrome 的内核）。 这使 Node.js 表现得非常出色。

- Node.js 应用程序运行于单个进程中，无需为每个请求创建新的线程。 Node.js 在其标准库中提供了一组异步的 I/O 原生功能（用以防止 JavaScript 代码被阻塞），并且 Node.js 中的库通常是使用非阻塞的范式编写的（从而使阻塞行为成为例外而不是规范）。

- Node.js 具有独特的优势，因为为浏览器编写 JavaScript 的数百万前端开发者现在除了客户端代码之外还可以编写服务器端代码，而无需学习完全不同的语言。

- 在 Node.js 中，可以毫无问题地使用新的 ECMAScript 标准，因为不必等待所有用户更新其浏览器，你可以通过更改 Node.js 版本来决定要使用的 ECMAScript 版本，并且还可以通过运行带有标志的 Node.js 来启用特定的实验中的特性。
### Node.js安装
安装参考node.js官网：[https://nodejs.org/zh-cn/](https://nodejs.org/zh-cn/)



## Request库安装
Request是Node.js的模块库，可完成http请求。
```
npm install request
```
使用方法：
```javascript
var request = require('request');
request('url', function (error, response, body) {
  if (!error && response.statusCode == 200) {
    console.log(body) 
  }
});
```

## Cheerio安装
cheerio是一个nodejs实现的类似jquery核心功能的一个模块，用它可以方便的将字符串解析成DOM文档，像用jquery一样方便的操作html。
安装方式：
```shell
npm install cheerio
```

## Iconv-lite安装
Iconv-lite是用来转化字符编码的库，具备如下几个特点：
- 不需要编辑原生代码
- 比node-iconv更快的速度
- 直观的编码/解码API
安装方式：
```shell
npm install iconv-lite
```
## 数据库安装
*本项目通过PostgreSQL关系型数据库存储爬取的结构化数据*


**PostgreSQL**简介：
-  PostgreSQL在业内通常也简称PG，是一个关系型数据库管理系统，适用于各种Linux操作系统、Windows、Solaris、BSD和Mac OS X。
- PostgreSQL遵循BSD许可，是一个开源软件，PostgreSQL作为全球第四大关系型数据库服务，正在以飞快的速度发展，目前已经广泛用在各个行业。

数据库安装：
官网上下载，官网链接[https://www.postgresql.org/](https://www.postgresql.org/)

# @[TOC](新闻爬虫以及爬取结果查询网站搭建（二）)(新闻爬虫以及爬取结果查询网站搭建（二）)

# 摘要
本章节将介绍爬虫的主要流程和代码实现。
爬虫流程如下：
- 读取种子页面
- 提取种子页面中包含的的新闻链接
- 爬取新闻链接的内容（标题，发表时间，内容等等）
- 将爬取后的内容整合成结构化的数据并存储到数据库中

在爬虫中首先构造模仿浏览器的request，通过header来防止网站屏蔽爬虫代码。request函数能够访问指定的url并且设置回调函数来处理得到的html页面。
```javascript
var headers = {
    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.65 Safari/537.36'
}
function request(url, callback) {
    var options = {
        url: url,
        encoding: null,
        headers: headers,
        timeout: 10000
    }
    myRequest(options, callback)
}
```
# 准备工作
## 数据库建表与连接
**建表语句(news、keywords两张表)**:
```sql
CREATE TABLE news (
   id_news serial UNIQUE,
   url text DEFAULT NULL UNIQUE,
   source_name varchar(50) DEFAULT NULL,
   source_encoding varchar(45) DEFAULT NULL,
   title varchar(100) DEFAULT NULL,
   publish_date date DEFAULT CURRENT_TIMESTAMP,
   content text,
  PRIMARY KEY (id_news)
);

CREATE TABLE keywords (
   id_word serial UNIQUE,
   id_news int,
   word varchar(50) DEFAULT NULL
);
```


**连接并配置数据库**

***本项目采用连接池的方法连接数据库。***


建立数据库连接池的好处：
1. 节约资源
2. 用户访问高效
- 首先安装数据库连接模版pg
```
npm install pg
```
- 创建连接池
```javascript
var pg = require('pg');

var config = {  
    host:"127.0.0.1",
    user:"root",
    database:"spider",
    password:"syz0615",
    port:5432,
    max:20, // 连接池最大连接数
    idleTimeoutMillis:3000, // 连接最大空闲时间 3s
}

var pool = new pg.Pool(config);
```


# 爬取网页（网易新闻、中新网财经频道、雪球网）
以**网易新闻网**为例详细展开说明：[网易新闻网](https://news.163.com/)

## 分析种子页面
![在这里插入图片描述](https://img-blog.csdnimg.cn/20210427194406895.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1Mzc4MDE3,size_16,color_FFFFFF,t_70#pic_center)

从上图我们可以看出，中间新闻的url均在"div class="main_center_news"下面，在该种子页面中，需要爬取每一个新闻的url。具体代码如下：


```javascript
var source_name = "网易新闻";
var myEncoding = "utf-8";
var seedURL = 'https://news.163.com/';
var seedURL_format = "$('a')";
var title_format = "$('title').text()";
var date_format = "$('html#ne_wrap').attr(\"data\-publishtime\")";//

var pgsql = require('../pg.js');
var Iconv = require('iconv-lite');
var myRequest = require('request');
var myCheerio = require('cheerio');
var url_reg = /\/(\d{2})\/(\d{4})\/(\d{2})\/([A-Z0-9]{16}).html/;
var regExp = /((\d{4}|\d{2})(\-|\/|\.)\d{1,2}\3\d{1,2})|(\d{4}年\d{1,2}月\d{1,2}日)/

var headers = {
    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.65 Safari/537.36'
}

function request(url, callback) {//request module fetching url
    var options = {
        url: url,
        encoding: null,
        headers: headers,
        timeout: 10000
    }
    myRequest(options, callback)
}

request(seedURL, function (err, res, data) {
    var buf = Iconv.encode(data, 'utf-8');
    var html = Iconv.decode(buf, myEncoding);
    var $ = myCheerio.load(html, { decodeEntities: true });
    try {
        seedurl_news = eval(seedURL_format);
    } catch (e) {  };

    seedurl_news.each(function(){
        var myURL = "";
        try {
            var href = "";
                href = $(this).attr("href");
                if (href == undefined) return;
                if (href.toLowerCase().indexOf('https://') >= 0 || href.toLowerCase().indexOf('http://') >= 0) myURL = href;
                else if (href.startsWith('//')) myURL = 'http:' + href; 
                else myURL = seedURL.substr(0, seedURL.lastIndexOf('/') + 1) + href; 
        }catch (e) {
        
        }
        if (!url_reg.test(myURL)) return;
        var news = {};
        news.url = myURL;
        news.source_name = source_name;
        news.source_encoding = myEncoding;
        var news_url_Sql = 'select url from news where url= $1';
        var news_url_Sql_Params = [myURL];
        pgsql.query(news_url_Sql, news_url_Sql_Params, function(err, result) {
            if (err) {
                console.log(err)
            } else {               
                Detail(news, myURL);
            }
        });
    });
});
```

## 分析新闻页面
获取新闻页面后，调用Detail函数来爬取新闻标题、作者、发布时间以及具体内容。

```javascript
function Detail(news, url) {
    request(url, function(err, res, data) {
        var $ = myCheerio.load(data, { decodeEntities: true});
        news.title = "";
        news.content = "";
        news.publish_date = new Date().toLocaleDateString().split('/').join('-');
        if (title_format == "") 
        news.title = ""
        else news.title = eval(title_format); 

        if(!isChinese(news.title[0]) && !isNumber(news.title[0]))
            return  ;
        if (date_format == "") news.publish_date = ""; 
        else news.publish_date = eval(date_format);
        if (news.publish_date) {
            news.publish_date = regExp.exec(news.publish_date)[0];
            news.publish_date = news.publish_date.replace('年', '-');
            news.publish_date = news.publish_date.replace('月', '-');
            news.publish_date = news.publish_date.replace('日', '');
        }
```

## 遇到的问题与解决方案
在爬取网页内容的过程中，遇到了title为乱码的情况。
解决方法如下：
- 通过isChinese和isNumber函数判断title字符串首字符是否为中文字符或者是数字，若都不是则直接返回。
```javascript
function isChinese(temp){
    var re=/[^\u4E00-\u9FA5]/;
    if (re.test(temp)) return false ;
    return true ;
}

//验证字符串是否是数字
function isNumber(theObj) {
    var reg = /^[0-9]+.?[0-9]*$/;
    if (reg.test(theObj)) {
        return true;
    }
    return false;
}
```

## 存储结果
如下图所示：
![在这里插入图片描述](https://img-blog.csdnimg.cn/2021042422280049.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1Mzc4MDE3,size_16,color_FFFFFF,t_70#pic_center)



# @[TOC](新闻爬虫以及爬取结果查询网站搭建（三）)(新闻爬虫以及爬取结果查询网站搭建（三）)

# 概要
本节主要介绍如何进行爬虫结果展示网站搭建。
有以下几部分：
1、前端网页设计
2、前端发送http post请求到后端
3、express构建后端访问pgsql
4、后端响应前端请求并在前端网页中用表格显示查询结果


# 前端网页设计
## 设计一
首先构造简单的前端，代码如下：
```html
<!DOCTYPE html>
<html>
<body>
<title>新闻检索</title>
<form action="http://127.0.0.1:3030/title" method="GET">
    <h1 align="center">根据新闻标题搜索:</h1>
    <div style="text-align:center;vertical-align:middel;"><input type="text" name="title" id="title_text">  </div>
    <div style="text-align:center;vertical-align:middel;"><input type="button" value="搜索" id="title_button"> </div>
</form>
<form action="http://127.0.0.1:3030/source_name" method="GET">
	<h1 align="center">根据网站名搜索:</h1>
    <div style="text-align:center;vertical-align:middel;"> <input type="text" name="source_name" id="source_name_text">  </div>
    <div style="text-align:center;vertical-align:middel;"> <input type="button" value="搜索" id="source_name_button"> </div>
</form>
<form action="http://127.0.0.1:3030/keyword" method="GET">
	<h1 align="center">根据新闻关键词搜索:</h1>
    <div style="text-align:center;vertical-align:middel;"> <input align="center" type="text" name="keyword" id="keyword_text">   </div>
    <div style="text-align:center;vertical-align:middel;"> <input align="center" type="button" value="搜索" id="keyword_button">  </div>
</form>
<form action="http://127.0.0.1:3030/keywords" method="GET">
	<h1 align="center">根据新闻关键词查看时间热度:</h1>
    <div style="text-align:center;vertical-align:middel;"> <input type="text" name="keyword" id="order_keyword_text">  </div>
    <div style="text-align:center;vertical-align:middel;"> <input type="button" value="搜索" id="order_keyword_button"> </div>
</form>
</body>
</html>
```

显示效果如下图所示：

![在这里插入图片描述](https://img-blog.csdnimg.cn/20210427183415832.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1Mzc4MDE3,size_16,color_FFFFFF,t_70#pic_center)

## 设计二
为了美观，在实现了基本功能后，后期又增加了博客中常见的动态图案。
```javascript
<script type="text/javascript" opacity = 1 color = "0,0,255"  src="//cdn.bootcss.com/canvas-nest.js/1.0.1/canvas-nest.min.js"></script>

```

## 对查询结果进行分页显示
前端网页使用了Js组件：bootstrap table。
Bootstrap table 是一款基于 Bootstrap 的 jQuery 表格插件，功能比较完备，能够实现数据异步获取，编辑，排序等一系列功能，最可贵的是，只需要一些简单的配置就可以实现一个功能完备的在线表格。 
详情可以参考[bootstrap table 官方文档](https://www.bootstrap-table.com.cn/doc/getting-started/introduction/)
前端代码如下：（以其中的一个表格实现为例）
```javascript
$("#title_button").click(function() {
            $('#soucename_table').bootstrapTable('destroy');
            $('#keyword_table').bootstrapTable('destroy');
            $('#keywords_table').bootstrapTable('destroy');
     var title = $("#title_text").val();
     var params = '/get_title?title=' + title;
     $(function(){
                    // console.log(params);
                    $("#title_table").empty();
                    $('#title_table').bootstrapTable({
                        url:params,
                        method:'GET',
                        pagination:true,
                        sidePagination:'client',
                        pageSize:5,
                        striped : true,
                        sortable : true,
                        sortOrder:"asc",
                        showRefresh:true,
                        search:true,
                        showToggle: true,
                        toolbar: '#toolbar',
                        showColumns : true,
                        columns:[{
                            field :'url',
                            title : 'url',
                            sortable : true
                        }, {
                            field:'title',
                            title:'title'
                        }, {
                            field:'source_name',
                            title:'source_name',
                            sortable : true
                        },{
                            field:'publish_date',
                            title:'publish_date',
                            sortable : true
                        }]
                    })
                });
     $.get(params, function(data) {
                    $('#title_table').bootstrapTable('refresh',{
                        url:params,
                        method:'GET',
                        pagination:true,
                        sidePagination:'client',
                        showRefresh:true,
                        columns:[{
                            field :'URl',
                            title :'url'
                        }, {
                            field:'Title',
                            title:'title'
                        }, {
                            field:'Source',
                            title:'source_name'
                        },{
                            field:'Date',
                            title:'publish_date'
                        }]
                    })
                    $("#title_table").append('<tr class="cardLayout"><td>url</td><td>source_name</td>' +
                       '<td>title</td><td>publish_date</td></tr>');
                });
                $('#title_text').val('');
  });
```
这段javascript代码内嵌在html网页中，当用户点击搜索新闻标题栏下的搜索按钮后，将会自动执行内嵌的javascript代码，并向后端服务器发送Get请求。后端服务器通过url获得title的信息并通过和数据库的交互实现查询功能，最后将查询结果发送http响应到前端，前端在接收到响应之后获取其中的参数信息并自动生成相应的表格信息。



# 最终网页效果如下：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20210427192921158.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1Mzc4MDE3,size_16,color_FFFFFF,t_70#pic_center)



# @[TOC](新闻爬虫以及爬取结果查询网站搭建（四）)(新闻爬虫以及爬取结果查询网站搭建（四）)

# 概要
本节主要介绍：
- 如何搭建网站后端
- 实现查询功能和时间热度分析。

# 网页后端框架
本次网站后端使用了Express框架
## 什么是Express:
- Express 是一个简洁而灵活的 node.js Web应用框架, 提供了一系列强大特性帮助你创建各种 Web 应用，和丰富的 HTTP 工具。
- 使用 Express 可以快速地搭建一个完整功能的网站。

## Express 框架核心特性：
- 可以设置中间件来响应HTTP请求
- 定义了路由表用于执行不同的 HTTP 请求动作。
- 可以通过向模板传递参数来动态渲染 HTML 页面。
### Express的使用：
- 首先创建目录作为当前工作目录
- 通过npm init命令为应用创建package.json 文件。
- 安装Express
```shell 
npm install express --save
```
- 文件中引入
```javascript
var express=require("express");
      var app=express();
```

### 框架中目录结构
- app.js: 启动文件,用来启动项目。
- package.json: 存储着工程的信息及模块依赖，当在 dependencies 中添加依赖的模块时， 运行 npm install ，npm 会检查当前目录下的 package.json，并自动安装所有指定的模块。
- node_modules: 存放 package.json 中安装的模块，当你在 package.json 添加依赖的模块并安装后，存放在这个文件夹下。
- public: 存放 image、css、js 等文件。
- routes: 存放路由文件。
- views: 存放视图文件或者说模板文件。

#### app.js
通过require()加装了express、path等模块，以及routes文件夹下的index.js和users.js路由文件。

- 生成一个express实例app。
var app = express();

- 设置 views 文件夹为存放视图文件的目录, 即存放模板文件的地方,__dirname 为全局变量,存储当前正在执行的脚本所在的目录。
app.set('views', path.join(__dirname, 'views'));

- 设置视图模板引擎为 ejs。
app.set('view engine', 'ejs');

- 加装日志中间件
app.use(logger('dev'));

- 加载解析urlencoded请求体的中间件。
app.use(bodyParser.urlencoded({ extended: false }));

- 加载解析cookie的中间件。
app.use(cookieParser());

-  设置public文件夹为存放静态文件的目录。
app.use(express.static(path.join(__dirname, 'public')));

-  路由控制器。
app.use('/', routes);
app.use('/users', users);


- 导出app实例供其他模块调用。
module.exports = app;

####  bin/www 文件：
- /usr/bin/env node：表明是 node 可执行文件。

- var debug = require(‘debug’)(‘blog’)：引入debug模块，打印调试日志。
- var app = require(‘../app’)：引入我们上面导出的app实例。
- app.set(‘port’, process.env.PORT || 3000)：设置端口号。
- 监听3000端口
```javascript
var port = normalizePort(process.env.PORT || '3000');
app.set('port', port);
```

#### routes/index.js 文件：
生成一个路由实例用来捕获访问主页的GET请求，导出这个路由并在app.js中通过
```javascript
var indexRouter = require('./routes/index');
app.use('/', indexRouter);
```
加载。


# 实现查询功能和时间热度分析
## 根据新闻标题进行搜索
采用模糊查询：
```javascript
var fetchSql = "select url,source_name,title,publish_date " + "from news where title like '%" + req.query.title + "%' Order By publish_date desc" ;
    pgsql.query_noparam(fetchSql, function(err, result, fields) {
        res.end(JSON.stringify(result.rows));
    });
```

## 根据网站名进行搜索
```javascript
 var fetchSql = "select url,source_name,title,publish_date " +
        "from news where source_name like '%" + req.query.source_name + "%' Order By publish_date desc" ;
    pgsql.query_noparam(fetchSql, function(err, result, fields) {
        // console.log("here");
        res.end(JSON.stringify(result.rows));
    });
```

## 根据关键词进行搜索
```javascript
res.writeHead(200, { 'Content-Type': 'text/html;charset=utf-8' }); 
        var fetch = "select news.url,news.title,news.source_name,keywords.word " +
        "from keywords,news where keywords.word like '%" + req.query.keyword + "%' and news.id_news=keywords.id_news" ;
        pgsql.query_noparam(fetch, function(err, result, fields) {
        // console.log("here");
            res.end(JSON.stringify(result));
        });
```

##  时间热度分析

```javascript
var fetchSql = "SELECT publish_date,count(*) as Num FROM news WHERE content like '%" + req.query.keyword + "%' group by publish_date order by publish_date desc;";
    pgsql.query_noparam(fetchSql, function(err, result, fields) {
        res.end(JSON.stringify(result));
    });
```